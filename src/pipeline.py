from __future__ import annotations

from pathlib import Path
from typing import List

from .lexer import tokenize
from .parser import parse_tokens
from .ir import generate_ir, generate_ir_quads
from .cfg import build_cfg, render_cfg
from . import lalr
from .utils import (
    StageResult,
    UserError,
    ensure_input_file,
    ensure_output_dir,
    write_csv_with_header,
    write_text_file,
    write_tokens_csv,
    write_action_goto_csv,
)

SUPPORTED_STAGES = ["lexer", "table", "parse", "ir", "cfg", "opt", "codegen", "all"]


def run_stage(stage: str, input_path: str) -> StageResult:
    """Dispatch a single stage and return basic metadata about the outputs."""
    normalized = stage.lower()
    if normalized not in SUPPORTED_STAGES:
        raise UserError(f"Error: unsupported stage '{stage}'")

    source_path = ensure_input_file(input_path)
    out_dir = ensure_output_dir(source_path)
    generated: List[Path] = []

    if normalized == "lexer":
        generated.append(_emit_tokens(source_path, out_dir))
    elif normalized == "table":
        generated.append(_emit_action_goto(out_dir))
    elif normalized == "parse":
        generated.append(_emit_parse_trace(source_path, out_dir))
    elif normalized == "ir":
        generated.append(generate_ir(source_path, out_dir))
    elif normalized == "cfg":
        generated.append(_emit_cfg(source_path, out_dir))
    elif normalized == "opt":
        generated.extend(_emit_opt(source_path, out_dir))
    elif normalized == "codegen":
        generated.append(_emit_target(out_dir))
    elif normalized == "all":
        generated.extend(_run_all(source_path, out_dir))

    return StageResult(stage=normalized, output_dir=out_dir, generated=generated)


def _emit_tokens(source_path: Path, out_dir: Path) -> Path:
    path = out_dir / "tokens.csv"
    tokens = tokenize(source_path)
    write_tokens_csv(path, tokens)
    return path


def _emit_action_goto(out_dir: Path) -> Path:
    path = out_dir / "action_goto.csv"
    _, terminals, nonterminals, action, goto_table = lalr.generate_tables()
    write_action_goto_csv(path, terminals, nonterminals, action, goto_table)
    return path


def _emit_parse_trace(source_path: Path, out_dir: Path) -> Path:
    path = out_dir / "parse_trace.txt"
    tokens = tokenize(source_path)
    parse_result = parse_tokens(tokens)
    write_text_file(path, parse_result.trace)
    return path


def _emit_ir(out_dir: Path) -> Path:
    raise UserError("Error: IR generation requires source file path")


def _emit_cfg(source_path: Path, out_dir: Path) -> Path:
    builder = generate_ir_quads(source_path)
    blocks = build_cfg(builder)
    cfg_path = out_dir / "cfg.txt"
    write_text_file(cfg_path, render_cfg(blocks))
    return cfg_path


def _emit_opt(source_path: Path, out_dir: Path) -> List[Path]:
    from .opt import optimize_ir

    ir_opt, report = optimize_ir(source_path, out_dir)
    return [ir_opt, report]


def _emit_target(out_dir: Path) -> Path:
    path = out_dir / "target.asm"
    content = (
        "; Target assembly (stub)\n"
        "; This file is generated by the codegen stage placeholder.\n"
    )
    write_text_file(path, content)
    return path


def _run_all(source_path: Path, out_dir: Path) -> List[Path]:
    generated: List[Path] = []
    generated.append(_emit_tokens(source_path, out_dir))
    generated.append(_emit_action_goto(out_dir))
    generated.append(_emit_parse_trace(source_path, out_dir))
    generated.append(generate_ir(source_path, out_dir))
    generated.append(_emit_cfg(source_path, out_dir))
    generated.extend(_emit_opt(out_dir))
    generated.append(_emit_target(out_dir))
    return generated
